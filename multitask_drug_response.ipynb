{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Multi-Task Drug Response Prediction\n",
    "\n",
    "**Goal**: Predict IC50 values for multiple drugs simultaneously\n",
    "\n",
    "**Why Multi-Task?**\n",
    "- Single-drug prediction can overfit to drug-specific patterns\n",
    "- Multi-task forces the model to learn generalizable biological features\n",
    "- More realistic evaluation: can the model predict drug responses broadly?\n",
    "\n",
    "**Problem Difficulty Options**:\n",
    "1. **Histology-based split**: Test on unseen cancer subtypes\n",
    "2. **Site-based split**: Test on unseen tissue origins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colab-setup-header",
   "metadata": {},
   "source": [
    "## Google Colab Setup\n",
    "Run the cell below first to set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colab-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab Setup - Run this cell first!\n",
    "import os\n",
    "\n",
    "IN_COLAB = 'google.colab' in str(get_ipython()) if 'get_ipython' in dir() else False\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    DATA_DIR = '/content/drive/MyDrive/bioai_data'\n",
    "    os.chdir(DATA_DIR)\n",
    "    print(f\"Working directory: {os.getcwd()}\")\n",
    "    print(f\"Files available: {os.listdir('.')}\")\n",
    "else:\n",
    "    print(\"Not running in Colab - using local paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading-header",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multi-omics feature data\n",
    "methexpr_df = pd.read_csv('ml_with_gene_expr.csv.gz',\n",
    "                          compression='gzip',\n",
    "                          index_col=0,\n",
    "                          low_memory=False)\n",
    "\n",
    "# Separate feature types\n",
    "metadata_cols = ['primary site', 'primary histology', 'cosmic_id']\n",
    "methylation_cols = [col for col in methexpr_df.columns if col.startswith('cg')]\n",
    "expression_cols = [col for col in methexpr_df.columns if col.startswith('expr_')]\n",
    "\n",
    "print(f\"Feature data shape: {methexpr_df.shape}\")\n",
    "print(f\"Methylation features: {len(methylation_cols)}\")\n",
    "print(f\"Expression features: {len(expression_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-drug-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load drug response data\n",
    "response_df = pd.read_csv('ML_dataset_methylation_drug_response.csv.gz',\n",
    "                          compression='gzip',\n",
    "                          index_col=0,\n",
    "                          low_memory=False)\n",
    "\n",
    "# Extract only drug columns (not methylation features or metadata)\n",
    "drug_cols = [col for col in response_df.columns \n",
    "             if not col.startswith('cg') and col not in metadata_cols]\n",
    "\n",
    "print(f\"Drug response data shape: {response_df.shape}\")\n",
    "print(f\"Total drugs available: {len(drug_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drug-selection-header",
   "metadata": {},
   "source": [
    "## Drug Selection by Coverage\n",
    "\n",
    "Select drugs with high coverage (most cell lines have IC50 values) to minimize missing data issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze drug coverage\n",
    "drug_response = response_df[drug_cols]\n",
    "coverage = drug_response.notna().sum().sort_values(ascending=False)\n",
    "total_samples = len(response_df)\n",
    "\n",
    "print(f\"Drug coverage statistics (of {total_samples} cell lines):\")\n",
    "print(f\"  Max coverage: {coverage.max()} ({100*coverage.max()/total_samples:.1f}%)\")\n",
    "print(f\"  Min coverage: {coverage.min()} ({100*coverage.min()/total_samples:.1f}%)\")\n",
    "print(f\"  Median coverage: {coverage.median():.0f} ({100*coverage.median()/total_samples:.1f}%)\")\n",
    "\n",
    "print(f\"\\nDrugs by coverage threshold:\")\n",
    "for thresh in [0.95, 0.90, 0.85, 0.80]:\n",
    "    n_drugs = (coverage > thresh * total_samples).sum()\n",
    "    print(f\"  >{thresh*100:.0f}% coverage: {n_drugs} drugs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "select-drugs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select drugs with high coverage\n",
    "# CONFIGURABLE: Adjust threshold to balance number of drugs vs missing data\n",
    "COVERAGE_THRESHOLD = 0.90  # 90% coverage = 288 drugs\n",
    "\n",
    "min_samples = int(COVERAGE_THRESHOLD * total_samples)\n",
    "selected_drugs = coverage[coverage >= min_samples].index.tolist()\n",
    "\n",
    "print(f\"Coverage threshold: {COVERAGE_THRESHOLD*100:.0f}% ({min_samples} samples minimum)\")\n",
    "print(f\"Selected drugs: {len(selected_drugs)}\")\n",
    "print(f\"\\nTop 10 drugs by coverage:\")\n",
    "for drug in selected_drugs[:10]:\n",
    "    print(f\"  {drug}: {coverage[drug]} ({100*coverage[drug]/total_samples:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "merge-header",
   "metadata": {},
   "source": [
    "## Merge Features and Drug Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "merge-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge feature data with drug responses (inner join on cell line names)\n",
    "df = methexpr_df.join(response_df[selected_drugs], how='inner')\n",
    "\n",
    "print(f\"Merged dataset shape: {df.shape}\")\n",
    "print(f\"Cell lines with both features and drug data: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare-multitask-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare multi-task target matrix (Y)\n",
    "Y_all = df[selected_drugs]\n",
    "\n",
    "# Find cell lines with complete drug response data (no missing values)\n",
    "complete_mask = Y_all.notna().all(axis=1)\n",
    "n_complete = complete_mask.sum()\n",
    "\n",
    "print(f\"Cell lines with complete drug data: {n_complete} ({100*n_complete/len(df):.1f}%)\")\n",
    "\n",
    "# Alternative: use cell lines with >X% drug coverage\n",
    "CELL_COVERAGE_THRESHOLD = 0.95\n",
    "cell_coverage = Y_all.notna().sum(axis=1) / len(selected_drugs)\n",
    "usable_cells = cell_coverage >= CELL_COVERAGE_THRESHOLD\n",
    "\n",
    "print(f\"Cell lines with >{CELL_COVERAGE_THRESHOLD*100:.0f}% drug coverage: {usable_cells.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cell lines with high drug coverage, impute remaining missing values\n",
    "df_filtered = df[usable_cells].copy()\n",
    "\n",
    "# Prepare features (X) and targets (Y)\n",
    "feature_cols = methylation_cols + expression_cols\n",
    "X = df_filtered[feature_cols]\n",
    "Y = df_filtered[selected_drugs]\n",
    "\n",
    "# Impute remaining missing drug values with drug-specific median\n",
    "Y_imputed = Y.fillna(Y.median())\n",
    "\n",
    "print(f\"Final dataset:\")\n",
    "print(f\"  X (features): {X.shape}\")\n",
    "print(f\"  Y (drug responses): {Y_imputed.shape}\")\n",
    "print(f\"  Missing values in Y after imputation: {Y_imputed.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-strategy-header",
   "metadata": {},
   "source": [
    "---\n",
    "# Split Strategy 1: Histology-Based (Unseen Cancer Subtypes)\n",
    "\n",
    "**Goal**: Test model's ability to predict drug response for cancer subtypes never seen during training.\n",
    "\n",
    "This is a challenging test because:\n",
    "- Different cancer subtypes have distinct molecular profiles\n",
    "- A rare cancer like chondrosarcoma may have completely different drug sensitivities than common cancers like lung adenocarcinoma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "histology-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histology distribution\n",
    "histology = df_filtered['primary histology']\n",
    "hist_counts = histology.value_counts(ascending=True)\n",
    "\n",
    "print(f\"Histology types: {len(hist_counts)}\")\n",
    "print(f\"\\nDistribution (ascending by count):\")\n",
    "print(hist_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "histology-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by histology: rare types go to test\n",
    "HISTOLOGY_SPLIT_THRESHOLD = 0.40  # 40% of histology types go to test\n",
    "\n",
    "split_idx = int(len(hist_counts) * HISTOLOGY_SPLIT_THRESHOLD)\n",
    "test_histologies = hist_counts.index[:split_idx].tolist()  # Rarest types\n",
    "train_histologies = hist_counts.index[split_idx:].tolist()  # Common types\n",
    "\n",
    "print(f\"Histology split at {HISTOLOGY_SPLIT_THRESHOLD*100:.0f}% threshold:\")\n",
    "print(f\"  Test histologies: {len(test_histologies)} types (rare, unseen)\")\n",
    "print(f\"  Train histologies: {len(train_histologies)} types (common)\")\n",
    "\n",
    "# Create train/test masks\n",
    "train_mask_hist = histology.isin(train_histologies)\n",
    "test_mask_hist = histology.isin(test_histologies)\n",
    "\n",
    "X_train_hist = X[train_mask_hist]\n",
    "X_test_hist = X[test_mask_hist]\n",
    "Y_train_hist = Y_imputed[train_mask_hist]\n",
    "Y_test_hist = Y_imputed[test_mask_hist]\n",
    "\n",
    "print(f\"\\nTrain samples: {len(X_train_hist)} ({100*len(X_train_hist)/len(X):.1f}%)\")\n",
    "print(f\"Test samples: {len(X_test_hist)} ({100*len(X_test_hist)/len(X):.1f}%)\")\n",
    "print(f\"\\nTest histology types: {test_histologies[:10]}...\" if len(test_histologies) > 10 else f\"\\nTest histology types: {test_histologies}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scaling-header",
   "metadata": {},
   "source": [
    "## Feature Scaling and Dimensionality Reduction\n",
    "\n",
    "**Critical**: Methylation (0-1) and expression (2-14) have different scales. Must scale before PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scale-hist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features (critical: methylation 0-1, expression 2-14)\n",
    "scaler_hist = RobustScaler()\n",
    "X_train_hist_scaled = scaler_hist.fit_transform(X_train_hist)\n",
    "X_test_hist_scaled = scaler_hist.transform(X_test_hist)\n",
    "\n",
    "# Dimensionality reduction with PCA\n",
    "N_COMPONENTS = 50  # More components for multi-task (capturing more variance)\n",
    "pca_hist = PCA(n_components=N_COMPONENTS)\n",
    "X_train_hist_pca = pca_hist.fit_transform(X_train_hist_scaled)\n",
    "X_test_hist_pca = pca_hist.transform(X_test_hist_scaled)\n",
    "\n",
    "print(f\"PCA variance explained: {pca_hist.explained_variance_ratio_.sum()*100:.1f}%\")\n",
    "print(f\"X_train shape after PCA: {X_train_hist_pca.shape}\")\n",
    "print(f\"X_test shape after PCA: {X_test_hist_pca.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multitask-eval-header",
   "metadata": {},
   "source": [
    "## Multi-Task Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_multitask(model, X_train, Y_train, X_test, Y_test):\n",
    "    \"\"\"\n",
    "    Evaluate multi-output regression model.\n",
    "    \n",
    "    Returns:\n",
    "        dict with per-drug and aggregate metrics\n",
    "    \"\"\"\n",
    "    # Predictions\n",
    "    Y_pred_train = model.predict(X_train)\n",
    "    Y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Convert to DataFrame for easier analysis\n",
    "    Y_pred_train_df = pd.DataFrame(Y_pred_train, columns=Y_train.columns, index=Y_train.index)\n",
    "    Y_pred_test_df = pd.DataFrame(Y_pred_test, columns=Y_test.columns, index=Y_test.index)\n",
    "    \n",
    "    # Per-drug metrics\n",
    "    train_r2_per_drug = []\n",
    "    test_r2_per_drug = []\n",
    "    test_mse_per_drug = []\n",
    "    \n",
    "    for drug in Y_train.columns:\n",
    "        train_r2_per_drug.append(r2_score(Y_train[drug], Y_pred_train_df[drug]))\n",
    "        test_r2_per_drug.append(r2_score(Y_test[drug], Y_pred_test_df[drug]))\n",
    "        test_mse_per_drug.append(mean_squared_error(Y_test[drug], Y_pred_test_df[drug]))\n",
    "    \n",
    "    # Aggregate metrics\n",
    "    results = {\n",
    "        'train_r2_mean': np.mean(train_r2_per_drug),\n",
    "        'train_r2_median': np.median(train_r2_per_drug),\n",
    "        'test_r2_mean': np.mean(test_r2_per_drug),\n",
    "        'test_r2_median': np.median(test_r2_per_drug),\n",
    "        'test_mse_mean': np.mean(test_mse_per_drug),\n",
    "        'test_r2_positive_frac': np.mean(np.array(test_r2_per_drug) > 0),\n",
    "        'per_drug_test_r2': dict(zip(Y_train.columns, test_r2_per_drug)),\n",
    "        'per_drug_test_mse': dict(zip(Y_train.columns, test_mse_per_drug)),\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_multitask_results(results, model_name):\n",
    "    \"\"\"Pretty print multi-task evaluation results.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Training R² (mean across drugs): {results['train_r2_mean']:.4f}\")\n",
    "    print(f\"Training R² (median): {results['train_r2_median']:.4f}\")\n",
    "    print(f\"\\nTest R² (mean across drugs): {results['test_r2_mean']:.4f}\")\n",
    "    print(f\"Test R² (median): {results['test_r2_median']:.4f}\")\n",
    "    print(f\"Test MSE (mean): {results['test_mse_mean']:.4f}\")\n",
    "    print(f\"\\nDrugs with positive test R²: {results['test_r2_positive_frac']*100:.1f}%\")\n",
    "    \n",
    "    # Show best and worst predicted drugs\n",
    "    sorted_drugs = sorted(results['per_drug_test_r2'].items(), key=lambda x: x[1], reverse=True)\n",
    "    print(f\"\\nTop 5 best predicted drugs:\")\n",
    "    for drug, r2 in sorted_drugs[:5]:\n",
    "        print(f\"  {drug}: R²={r2:.4f}\")\n",
    "    print(f\"\\nTop 5 worst predicted drugs:\")\n",
    "    for drug, r2 in sorted_drugs[-5:]:\n",
    "        print(f\"  {drug}: R²={r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "models-header",
   "metadata": {},
   "source": [
    "## Model Training: Histology-Based Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark-df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize benchmark results\n",
    "benchmark_hist = pd.DataFrame(columns=[\n",
    "    'Model', 'Train R² (mean)', 'Train R² (median)', \n",
    "    'Test R² (mean)', 'Test R² (median)', 'Test MSE (mean)', '% Drugs R²>0'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ridge-header",
   "metadata": {},
   "source": [
    "### Ridge Regression (Multi-Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ridge-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Ridge regression handles multi-output natively\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train_hist_pca, Y_train_hist)\n",
    "\n",
    "results_ridge = evaluate_multitask(ridge, X_train_hist_pca, Y_train_hist, X_test_hist_pca, Y_test_hist)\n",
    "print_multitask_results(results_ridge, 'Ridge Regression')\n",
    "\n",
    "benchmark_hist.loc[len(benchmark_hist)] = [\n",
    "    'Ridge', results_ridge['train_r2_mean'], results_ridge['train_r2_median'],\n",
    "    results_ridge['test_r2_mean'], results_ridge['test_r2_median'],\n",
    "    results_ridge['test_mse_mean'], results_ridge['test_r2_positive_frac']*100\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rf-header",
   "metadata": {},
   "source": [
    "### Random Forest (Multi-Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rf-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# RandomForest handles multi-output natively\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train_hist_pca, Y_train_hist)\n",
    "\n",
    "results_rf = evaluate_multitask(rf, X_train_hist_pca, Y_train_hist, X_test_hist_pca, Y_test_hist)\n",
    "print_multitask_results(results_rf, 'Random Forest')\n",
    "\n",
    "benchmark_hist.loc[len(benchmark_hist)] = [\n",
    "    'Random Forest', results_rf['train_r2_mean'], results_rf['train_r2_median'],\n",
    "    results_rf['test_r2_mean'], results_rf['test_r2_median'],\n",
    "    results_rf['test_mse_mean'], results_rf['test_r2_positive_frac']*100\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xgb-header",
   "metadata": {},
   "source": [
    "### XGBoost (Multi-Output via MultiOutputRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xgb-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# XGBoost needs MultiOutputRegressor wrapper for multi-output\n",
    "# Note: This trains a separate XGBoost per drug - computationally intensive\n",
    "xgb_base = XGBRegressor(\n",
    "    n_estimators=100, \n",
    "    max_depth=5, \n",
    "    learning_rate=0.1,\n",
    "    random_state=42, \n",
    "    tree_method='hist', \n",
    "    device='cuda',\n",
    "    verbosity=0\n",
    ")\n",
    "xgb_multi = MultiOutputRegressor(xgb_base, n_jobs=1)  # n_jobs=1 since GPU handles parallelism\n",
    "\n",
    "print(f\"Training XGBoost for {len(selected_drugs)} drugs (GPU-accelerated)...\")\n",
    "xgb_multi.fit(X_train_hist_pca, Y_train_hist)\n",
    "\n",
    "results_xgb = evaluate_multitask(xgb_multi, X_train_hist_pca, Y_train_hist, X_test_hist_pca, Y_test_hist)\n",
    "print_multitask_results(results_xgb, 'XGBoost (Multi-Output)')\n",
    "\n",
    "benchmark_hist.loc[len(benchmark_hist)] = [\n",
    "    'XGBoost', results_xgb['train_r2_mean'], results_xgb['train_r2_median'],\n",
    "    results_xgb['test_r2_mean'], results_xgb['test_r2_median'],\n",
    "    results_xgb['test_mse_mean'], results_xgb['test_r2_positive_frac']*100\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "show-benchmark-hist",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BENCHMARK RESULTS: HISTOLOGY-BASED SPLIT (Unseen Cancer Subtypes)\")\n",
    "print(f\"Train: {len(X_train_hist)} samples | Test: {len(X_test_hist)} samples\")\n",
    "print(f\"Drugs: {len(selected_drugs)} | PCA components: {N_COMPONENTS}\")\n",
    "print(\"=\"*70)\n",
    "display(benchmark_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "site-split-header",
   "metadata": {},
   "source": [
    "---\n",
    "# Split Strategy 2: Primary Site-Based (Unseen Tissue Origins)\n",
    "\n",
    "**Goal**: Test model's ability to predict drug response for tissues never seen during training.\n",
    "\n",
    "This tests a different kind of generalization:\n",
    "- Can a model trained on lung/blood cancers predict for pancreas/thyroid cancers?\n",
    "- Different organs have distinct gene expression and methylation patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "site-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary site distribution\n",
    "primary_site = df_filtered['primary site']\n",
    "site_counts = primary_site.value_counts(ascending=True)\n",
    "\n",
    "print(f\"Primary sites: {len(site_counts)}\")\n",
    "print(f\"\\nDistribution (ascending by count):\")\n",
    "print(site_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "site-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by primary site: rare tissues go to test\n",
    "SITE_SPLIT_THRESHOLD = 0.40  # 40% of sites go to test\n",
    "\n",
    "site_split_idx = int(len(site_counts) * SITE_SPLIT_THRESHOLD)\n",
    "test_sites = site_counts.index[:site_split_idx].tolist()  # Rarest sites\n",
    "train_sites = site_counts.index[site_split_idx:].tolist()  # Common sites\n",
    "\n",
    "print(f\"Site split at {SITE_SPLIT_THRESHOLD*100:.0f}% threshold:\")\n",
    "print(f\"  Test sites: {len(test_sites)} ({test_sites})\")\n",
    "print(f\"  Train sites: {len(train_sites)} ({train_sites})\")\n",
    "\n",
    "# Create train/test masks\n",
    "train_mask_site = primary_site.isin(train_sites)\n",
    "test_mask_site = primary_site.isin(test_sites)\n",
    "\n",
    "X_train_site = X[train_mask_site]\n",
    "X_test_site = X[test_mask_site]\n",
    "Y_train_site = Y_imputed[train_mask_site]\n",
    "Y_test_site = Y_imputed[test_mask_site]\n",
    "\n",
    "print(f\"\\nTrain samples: {len(X_train_site)} ({100*len(X_train_site)/len(X):.1f}%)\")\n",
    "print(f\"Test samples: {len(X_test_site)} ({100*len(X_test_site)/len(X):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scale-site",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale and PCA for site-based split\n",
    "scaler_site = RobustScaler()\n",
    "X_train_site_scaled = scaler_site.fit_transform(X_train_site)\n",
    "X_test_site_scaled = scaler_site.transform(X_test_site)\n",
    "\n",
    "pca_site = PCA(n_components=N_COMPONENTS)\n",
    "X_train_site_pca = pca_site.fit_transform(X_train_site_scaled)\n",
    "X_test_site_pca = pca_site.transform(X_test_site_scaled)\n",
    "\n",
    "print(f\"PCA variance explained: {pca_site.explained_variance_ratio_.sum()*100:.1f}%\")\n",
    "print(f\"X_train shape after PCA: {X_train_site_pca.shape}\")\n",
    "print(f\"X_test shape after PCA: {X_test_site_pca.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "site-models-header",
   "metadata": {},
   "source": [
    "## Model Training: Site-Based Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark-site-df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize benchmark results for site-based split\n",
    "benchmark_site = pd.DataFrame(columns=[\n",
    "    'Model', 'Train R² (mean)', 'Train R² (median)', \n",
    "    'Test R² (mean)', 'Test R² (median)', 'Test MSE (mean)', '% Drugs R²>0'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ridge-site",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "ridge_site = Ridge(alpha=1.0)\n",
    "ridge_site.fit(X_train_site_pca, Y_train_site)\n",
    "\n",
    "results_ridge_site = evaluate_multitask(ridge_site, X_train_site_pca, Y_train_site, X_test_site_pca, Y_test_site)\n",
    "print_multitask_results(results_ridge_site, 'Ridge Regression (Site Split)')\n",
    "\n",
    "benchmark_site.loc[len(benchmark_site)] = [\n",
    "    'Ridge', results_ridge_site['train_r2_mean'], results_ridge_site['train_r2_median'],\n",
    "    results_ridge_site['test_r2_mean'], results_ridge_site['test_r2_median'],\n",
    "    results_ridge_site['test_mse_mean'], results_ridge_site['test_r2_positive_frac']*100\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rf-site",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_site = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "rf_site.fit(X_train_site_pca, Y_train_site)\n",
    "\n",
    "results_rf_site = evaluate_multitask(rf_site, X_train_site_pca, Y_train_site, X_test_site_pca, Y_test_site)\n",
    "print_multitask_results(results_rf_site, 'Random Forest (Site Split)')\n",
    "\n",
    "benchmark_site.loc[len(benchmark_site)] = [\n",
    "    'Random Forest', results_rf_site['train_r2_mean'], results_rf_site['train_r2_median'],\n",
    "    results_rf_site['test_r2_mean'], results_rf_site['test_r2_median'],\n",
    "    results_rf_site['test_mse_mean'], results_rf_site['test_r2_positive_frac']*100\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xgb-site",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgb_base_site = XGBRegressor(\n",
    "    n_estimators=100, \n",
    "    max_depth=5, \n",
    "    learning_rate=0.1,\n",
    "    random_state=42, \n",
    "    tree_method='hist', \n",
    "    device='cuda',\n",
    "    verbosity=0\n",
    ")\n",
    "xgb_multi_site = MultiOutputRegressor(xgb_base_site, n_jobs=1)\n",
    "\n",
    "print(f\"Training XGBoost for {len(selected_drugs)} drugs (GPU-accelerated)...\")\n",
    "xgb_multi_site.fit(X_train_site_pca, Y_train_site)\n",
    "\n",
    "results_xgb_site = evaluate_multitask(xgb_multi_site, X_train_site_pca, Y_train_site, X_test_site_pca, Y_test_site)\n",
    "print_multitask_results(results_xgb_site, 'XGBoost (Site Split)')\n",
    "\n",
    "benchmark_site.loc[len(benchmark_site)] = [\n",
    "    'XGBoost', results_xgb_site['train_r2_mean'], results_xgb_site['train_r2_median'],\n",
    "    results_xgb_site['test_r2_mean'], results_xgb_site['test_r2_median'],\n",
    "    results_xgb_site['test_mse_mean'], results_xgb_site['test_r2_positive_frac']*100\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "show-benchmark-site",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BENCHMARK RESULTS: SITE-BASED SPLIT (Unseen Tissue Origins)\")\n",
    "print(f\"Train: {len(X_train_site)} samples | Test: {len(X_test_site)} samples\")\n",
    "print(f\"Drugs: {len(selected_drugs)} | PCA components: {N_COMPONENTS}\")\n",
    "print(\"=\"*70)\n",
    "display(benchmark_site)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-header",
   "metadata": {},
   "source": [
    "---\n",
    "# Final Comparison: Split Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"MULTI-TASK DRUG RESPONSE PREDICTION: FINAL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nDataset: {len(X)} cell lines × {len(selected_drugs)} drugs\")\n",
    "print(f\"Features: {X.shape[1]} (methylation + expression) → {N_COMPONENTS} PCA components\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"HISTOLOGY-BASED SPLIT (Unseen Cancer Subtypes)\")\n",
    "print(f\"Train: {len(X_train_hist)} | Test: {len(X_test_hist)} ({100*len(X_test_hist)/len(X):.1f}%)\")\n",
    "print(\"-\"*80)\n",
    "display(benchmark_hist)\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"SITE-BASED SPLIT (Unseen Tissue Origins)\")\n",
    "print(f\"Train: {len(X_train_site)} | Test: {len(X_test_site)} ({100*len(X_test_site)/len(X):.1f}%)\")\n",
    "print(\"-\"*80)\n",
    "display(benchmark_site)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "Multi-task drug response prediction is MUCH harder than single-drug prediction:\n",
    "\n",
    "1. EXPECTED: Low R² values (even negative) are normal for this task\n",
    "   - Negative R² = model worse than predicting mean for all samples\n",
    "   - This is a hard problem - SOTA methods struggle here too\n",
    "\n",
    "2. METRIC TO FOCUS ON: '% Drugs R²>0'\n",
    "   - What fraction of drugs can the model predict better than baseline?\n",
    "   - 50%+ is reasonable, 70%+ is good\n",
    "\n",
    "3. SPLIT COMPARISON:\n",
    "   - Histology split: Tests cancer subtype generalization\n",
    "   - Site split: Tests tissue origin generalization\n",
    "   - Worse performance on site split suggests tissue-specific drug responses\n",
    "\n",
    "4. NEXT STEPS for improvement:\n",
    "   - Neural network architectures (can learn drug-drug relationships)\n",
    "   - Drug structure features (molecular fingerprints)\n",
    "   - Pathway-aware features\n",
    "   - Transfer learning from larger datasets\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "per-drug-analysis-header",
   "metadata": {},
   "source": [
    "## Per-Drug Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "per-drug-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare per-drug R² between split strategies (using best model from each)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get per-drug R² from XGBoost (typically best performer)\n",
    "hist_r2 = pd.Series(results_xgb['per_drug_test_r2'])\n",
    "site_r2 = pd.Series(results_xgb_site['per_drug_test_r2'])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram of per-drug R²\n",
    "axes[0].hist(hist_r2, bins=30, alpha=0.7, label='Histology Split', color='blue')\n",
    "axes[0].hist(site_r2, bins=30, alpha=0.7, label='Site Split', color='orange')\n",
    "axes[0].axvline(x=0, color='red', linestyle='--', label='Baseline (R²=0)')\n",
    "axes[0].set_xlabel('Test R² per Drug')\n",
    "axes[0].set_ylabel('Number of Drugs')\n",
    "axes[0].set_title('Distribution of Per-Drug Test R²')\n",
    "axes[0].legend()\n",
    "\n",
    "# Scatter: Histology R² vs Site R²\n",
    "common_drugs = hist_r2.index.intersection(site_r2.index)\n",
    "axes[1].scatter(hist_r2[common_drugs], site_r2[common_drugs], alpha=0.5)\n",
    "axes[1].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1].axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1].plot([-1, 1], [-1, 1], 'k--', alpha=0.3, label='y=x')\n",
    "axes[1].set_xlabel('Test R² (Histology Split)')\n",
    "axes[1].set_ylabel('Test R² (Site Split)')\n",
    "axes[1].set_title('Per-Drug R²: Histology vs Site Split')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nDrugs easier to predict with Histology split: {(hist_r2 > site_r2).sum()}\")\n",
    "print(f\"Drugs easier to predict with Site split: {(site_r2 > hist_r2).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-results-header",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save benchmark results\n",
    "benchmark_hist.to_csv('multitask_benchmark_histology_split.csv', index=False)\n",
    "benchmark_site.to_csv('multitask_benchmark_site_split.csv', index=False)\n",
    "\n",
    "# Save per-drug results\n",
    "per_drug_results = pd.DataFrame({\n",
    "    'drug': hist_r2.index,\n",
    "    'test_r2_histology_split': hist_r2.values,\n",
    "    'test_r2_site_split': site_r2.values\n",
    "})\n",
    "per_drug_results.to_csv('multitask_per_drug_results.csv', index=False)\n",
    "\n",
    "print(\"Results saved:\")\n",
    "print(\"  - multitask_benchmark_histology_split.csv\")\n",
    "print(\"  - multitask_benchmark_site_split.csv\")\n",
    "print(\"  - multitask_per_drug_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
